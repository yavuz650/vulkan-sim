{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from multiprocessing import Process, Queue , Array\n",
    "import pickle\n",
    "\n",
    "class RayData:\n",
    "  def __init__(self, tid, ray_orig_x, ray_orig_y, ray_orig_z, ray_dir_x, ray_dir_y, ray_dir_z):\n",
    "    self.tid = tid\n",
    "\n",
    "    self.ray_orig_x=ray_orig_x\n",
    "    self.ray_orig_y=ray_orig_y\n",
    "    self.ray_orig_z=ray_orig_z\n",
    "\n",
    "    self.ray_dir_x=ray_dir_x\n",
    "    self.ray_dir_y=ray_dir_y\n",
    "    self.ray_dir_z=ray_dir_z\n",
    "\n",
    "  def __eq__(self, other):\n",
    "    if isinstance(other, RayData):\n",
    "      # Compare attributes for equality\n",
    "      return  self.tid == other.tid and \\\n",
    "              self.ray_orig_x == other.ray_orig_x and \\\n",
    "              self.ray_orig_y == other.ray_orig_y and \\\n",
    "              self.ray_orig_z == other.ray_orig_z and \\\n",
    "              self.ray_dir_x == other.ray_dir_x and \\\n",
    "              self.ray_dir_y == other.ray_dir_y and \\\n",
    "              self.ray_dir_z == other.ray_dir_z\n",
    "    return False\n",
    "  \n",
    "  def __str__(self):\n",
    "    # Customize the string representation for printing\n",
    "    return f\"ray_data instance: {self.tid}, {self.ray_orig_x}, {self.ray_orig_y}, {self.ray_orig_z}, {self.ray_dir_x}, {self.ray_dir_y}, {self.ray_dir_z}\"\n",
    "\n",
    "class MemEntry:\n",
    "  def __init__(self, address, size, type):\n",
    "    self.entry = [address, size, type]\n",
    "\n",
    "  def __eq__(self, other):\n",
    "    if isinstance(other, MemEntry):\n",
    "      # Compare attributes for equality\n",
    "      return self.entry[0] == other.entry[0] and self.entry[1] == other.entry[1]\n",
    "    return False\n",
    "  \n",
    "  def __str__(self):\n",
    "    # Customize the string representation for printing\n",
    "    return f\"mem_entry instance: {self.entry}\"\n",
    "\n",
    "class TraceRayEntry:\n",
    "  def __init__(self, ray_data: RayData, mem_entries: List[MemEntry]):\n",
    "    self.ray_data = ray_data\n",
    "    self.mem_entries = mem_entries\n",
    "\n",
    "  def __str__(self):\n",
    "    # Customize the string representation for printing\n",
    "    return f\"trace_ray_entry instance: {self.ray_data}, {self.mem_entries}\"\n",
    "\n",
    "class HashedRay:\n",
    "  def __init__(self, hash, tid: int, rayid: int):\n",
    "    self.hash = hash\n",
    "    self.tid = tid # thread id, index to the thread_list\n",
    "    self.rayid = rayid # ray id, index to the entry in the thread_list\n",
    "\n",
    "  def __str__(self):\n",
    "    return f\"HashedRay: hash:{self.hash}, tid:{self.tid}, rayid:{self.rayid}\"\n",
    "\n",
    "# Quantize direction to a sphere - xyz to theta and phi\n",
    "# `theta_bits` is used for theta, `theta_bits` + 1 is used for phi, for a total of\n",
    "# 2 * `theta_bits` + 1 bits\n",
    "def hash_direction_spherical(d, num_sphere_bits):\n",
    "  theta_bits = np.uint32(num_sphere_bits)\n",
    "  phi_bits = np.uint32(theta_bits + 1)\n",
    "\n",
    "  theta = np.uint64(np.arccos(np.clip(d[2], -1.0, 1.0)) / np.pi * 180)\n",
    "  phi = np.uint64((np.arctan2(d[1], d[0]) + np.pi) / np.pi * 180)\n",
    "  q_theta = theta >> np.uint64(8 - theta_bits)\n",
    "  q_phi = phi >> np.uint64(9 - phi_bits)\n",
    "\n",
    "  return (q_phi << theta_bits) | q_theta\n",
    "\n",
    "def hash_origin_grid(o, min_val, max_val, num_bits):\n",
    "  grid_size = 1 << num_bits\n",
    "\n",
    "  hash_o_x = np.uint64(np.clip((o[0] - min_val[0]) / (max_val[0] - min_val[0]) * grid_size, 0.0, float(grid_size) - 1))\n",
    "  hash_o_y = np.uint64(np.clip((o[1] - min_val[1]) / (max_val[1] - min_val[1]) * grid_size, 0.0, float(grid_size) - 1))\n",
    "  hash_o_z = np.uint64(np.clip((o[2] - min_val[2]) / (max_val[2] - min_val[2]) * grid_size, 0.0, float(grid_size) - 1))\n",
    "  \n",
    "  hash_value = (hash_o_x << np.uint32((2 * num_bits))) | (hash_o_y << np.uint32(num_bits)) | hash_o_z\n",
    "  return np.uint64(hash_value)\n",
    "\n",
    "def hash_grid_spherical(ray_direction, ray_origin, min_val, max_val, num_grid_bits, num_sphere_bits):\n",
    "  hash_d = hash_direction_spherical(ray_direction, num_sphere_bits)\n",
    "  hash_o = hash_origin_grid(ray_origin, min_val, max_val, num_grid_bits)\n",
    "  hash_value = hash_o ^ hash_d\n",
    "\n",
    "  return hash_value\n",
    "\n",
    "def parse_csv(csv, number_of_threads):\n",
    "  thread_list = [[] for _ in range(number_of_threads)]\n",
    "  mem_entries = []\n",
    "  last_idx = csv[0][Indices.IDX]\n",
    "  last_tid = csv[0][Indices.TID]\n",
    "  last_ray_data = RayData(csv[0][Indices.TID],\n",
    "                           csv[0][Indices.RAY_ORIG_X],\n",
    "                           csv[0][Indices.RAY_ORIG_Y],\n",
    "                           csv[0][Indices.RAY_ORIG_Z],\n",
    "                           csv[0][Indices.RAY_DIR_X],\n",
    "                           csv[0][Indices.RAY_DIR_Y],\n",
    "                           csv[0][Indices.RAY_DIR_Z])\n",
    "  print(\"Parsing the csv...\")\n",
    "  for entry in csv:\n",
    "    if(last_idx != entry[Indices.IDX]):\n",
    "      thread_list[last_tid].append(TraceRayEntry(last_ray_data,mem_entries[:]))\n",
    "      mem_entries.clear()\n",
    "      last_ray_data = RayData(entry[Indices.TID],\n",
    "                               entry[Indices.RAY_ORIG_X],\n",
    "                               entry[Indices.RAY_ORIG_Y],\n",
    "                               entry[Indices.RAY_ORIG_Z],\n",
    "                               entry[Indices.RAY_DIR_X],\n",
    "                               entry[Indices.RAY_DIR_Y],\n",
    "                               entry[Indices.RAY_DIR_Z])\n",
    "      last_idx = entry[Indices.IDX]\n",
    "      last_tid = entry[Indices.TID]\n",
    "    \n",
    "    mem_entries.append(MemEntry(entry[Indices.ADDR],entry[Indices.SIZE],entry[Indices.TYPE]))\n",
    "  print(\"Finished parsing the csv...\")\n",
    "  return thread_list\n",
    "\n",
    "class Indices:\n",
    "  IDX = 0\n",
    "  TID = 1\n",
    "  ADDR = 2\n",
    "  SIZE = 3\n",
    "  TYPE = 4\n",
    "  RAY_ORIG_X = 5\n",
    "  RAY_ORIG_Y = 6\n",
    "  RAY_ORIG_Z = 7\n",
    "  RAY_DIR_X = 8\n",
    "  RAY_DIR_Y = 9\n",
    "  RAY_DIR_Z = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_bunny_stereo():\n",
    "  print(\"Loading bunny\")\n",
    "  # Read the first CSV file into a DataFrame\n",
    "  df1 = pd.read_csv('../../outputs/bunny_left_eye_mem_access.csv')\n",
    "  # Convert the DataFrame to a list of lists\n",
    "  csv1 = df1.values.tolist()\n",
    "  number_of_threads1 = df1['tid'].nunique()\n",
    "\n",
    "  thread_list1 = parse_csv(csv1,number_of_threads1)\n",
    "\n",
    "  # Read the second CSV file into a DataFrame\n",
    "  df2 = pd.read_csv('../../outputs/bunny_right_eye_mem_access.csv')\n",
    "  # Convert the DataFrame to a list of lists\n",
    "  csv2 = df2.values.tolist()\n",
    "  number_of_threads2 = df2['tid'].nunique()\n",
    "\n",
    "  thread_list2 = parse_csv(csv2,number_of_threads2)\n",
    "\n",
    "  min_val = np.array([0.0, 0.0, -555.0])  # bunny min values\n",
    "  max_val = np.array([556.0, 556.0, 1.0])  # bunny max values\n",
    "\n",
    "  return thread_list1,thread_list2,min_val,max_val\n",
    "\n",
    "def load_sponza_stereo():\n",
    "  print(\"Loading sponza\")\n",
    "  # Read the first CSV file into a DataFrame\n",
    "  df1 = pd.read_csv('../../outputs/sponza_left_eye_mem_access.csv')\n",
    "  # Convert the DataFrame to a list of lists\n",
    "  csv1 = df1.values.tolist()\n",
    "  number_of_threads1 = df1['tid'].nunique()\n",
    "\n",
    "  thread_list1 = parse_csv(csv1,number_of_threads1)\n",
    "\n",
    "  # Read the second CSV file into a DataFrame\n",
    "  df2 = pd.read_csv('../../outputs/sponza_right_eye_mem_access.csv')\n",
    "  # Convert the DataFrame to a list of lists\n",
    "  csv2 = df2.values.tolist()\n",
    "  number_of_threads2 = df2['tid'].nunique()\n",
    "\n",
    "  thread_list2 = parse_csv(csv2,number_of_threads2)\n",
    "\n",
    "  min_val = np.array([-1105.42603,-126.442497,-1920.94592]) # sponza min values\n",
    "  max_val = np.array([1198.57397,1433.5575,1807.05408]) # sponza max values\n",
    "\n",
    "  return thread_list1,thread_list2,min_val,max_val\n",
    "\n",
    "def hash_rays(thread_list1, min_val, max_val, num_grid_bits, num_sphere_bits):\n",
    "  hash_bits = max(3*num_grid_bits,2*num_sphere_bits+1)\n",
    "  print(f\"Hashing rays...({hash_bits} bits)\")\n",
    "  hash_dict = {}\n",
    "  for i in range(2**hash_bits):\n",
    "    hash_dict[i] = []\n",
    "\n",
    "  for tid,thread in enumerate(thread_list1):\n",
    "    for rayid,ray in enumerate(thread):\n",
    "      # only hash if the ray intersects the scene\n",
    "      if(any(obj.entry[2] == 5 for obj in ray.mem_entries)):\n",
    "        hash_value = hash_grid_spherical(np.array([ray.ray_data.ray_dir_x, ray.ray_data.ray_dir_y, ray.ray_data.ray_dir_z]),\n",
    "                                         np.array([ray.ray_data.ray_orig_x, ray.ray_data.ray_orig_y, ray.ray_data.ray_orig_z]),\n",
    "                                         min_val, max_val,num_grid_bits,num_sphere_bits)\n",
    "        hash_dict[hash_value].append(HashedRay(hash_value, tid, rayid))\n",
    "\n",
    "  return hash_dict\n",
    "\n",
    "def hash_rays_random(thread_list1, num_grid_bits, num_sphere_bits):\n",
    "  hash_bits = max(3*num_grid_bits,2*num_sphere_bits+1)\n",
    "  print(f\"Hashing rays randomly...({hash_bits} bits)\")\n",
    "  hash_dict = {}\n",
    "  for i in range(2**hash_bits):\n",
    "    hash_dict[i] = []\n",
    "\n",
    "  for tid,thread in enumerate(thread_list1):\n",
    "    for rayid,ray in enumerate(thread):\n",
    "      # only hash if the ray intersects the scene\n",
    "      if(any(obj.entry[2] == 5 for obj in ray.mem_entries)):\n",
    "        hash_value = random.randint(0, 2**hash_bits-1)\n",
    "        hash_dict[hash_value].append(HashedRay(hash_value, tid, rayid))\n",
    "\n",
    "  return hash_dict\n",
    "\n",
    "def check_matches(list1: List[MemEntry], list2: List[MemEntry]):\n",
    "  num_matches = 0\n",
    "  length = len(list2) if len(list2) < len(list1) else len(list1)\n",
    "  for idx in range(length):\n",
    "      if(list1[idx].entry[0] == list2[idx].entry[0] and list1[idx].entry[1] == list2[idx].entry[1]):\n",
    "        num_matches += 1\n",
    "      else:\n",
    "        break\n",
    "\n",
    "  return num_matches\n",
    "\n",
    "def find_all_matches_best(hash_dict1, hash_dict2, thread_list1, thread_list2):\n",
    "  matches_list = []\n",
    "  lengths_list = []\n",
    "  tid_list = []\n",
    "  rayid_list = []\n",
    "  for hash2,hash_list2 in hash_dict2.items():\n",
    "    num_matching_hashes = len(hash_dict1[hash2]) if len(hash_dict1[hash2]) > 0 else 1\n",
    "    for ray2 in hash_list2:\n",
    "      total_matches = 0\n",
    "      for ray1 in hash_dict1[hash2]:\n",
    "        matches = check_matches(thread_list1[ray1.tid][ray1.rayid].mem_entries, thread_list2[ray2.tid][ray2.rayid].mem_entries)\n",
    "        total_matches += matches\n",
    "\n",
    "      matches_list.append(np.int32(np.ceil(total_matches/num_matching_hashes)))\n",
    "      lengths_list.append(len(thread_list2[ray2.tid][ray2.rayid].mem_entries))\n",
    "\n",
    "  return np.array(matches_list),np.array(lengths_list),np.array(tid_list),np.array(rayid_list)   \n",
    "\n",
    "def find_all_matches_nearest(hash_dict1, hash_dict2, thread_list1, thread_list2):\n",
    "  matches_list = []\n",
    "  lengths_list = []\n",
    "  tid_list = []\n",
    "  rayid_list = []\n",
    "  for hash2,hash_list2 in hash_dict2.items():\n",
    "    nearest_matches = 0\n",
    "    nearest_tid = 0\n",
    "    nearest_rayid = 0\n",
    "    for ray2 in hash_list2:\n",
    "      min_distance = 32768\n",
    "      nearest_len = len(thread_list2[ray2.tid][ray2.rayid].mem_entries)\n",
    "      for ray1 in hash_dict1[hash2]:\n",
    "        if abs(ray1.tid-ray2.tid) < min_distance:\n",
    "          min_distance = abs(ray1.tid-ray2.tid)\n",
    "          matches = check_matches(thread_list1[ray1.tid][ray1.rayid].mem_entries, thread_list2[ray2.tid][ray2.rayid].mem_entries)\n",
    "          nearest_matches = matches\n",
    "          nearest_tid = ray1.tid\n",
    "          nearest_rayid = ray1.rayid\n",
    "      matches_list.append(nearest_matches)\n",
    "      lengths_list.append(nearest_len)\n",
    "      tid_list.append(nearest_tid)\n",
    "      rayid_list.append(nearest_rayid)\n",
    "\n",
    "  return np.array(matches_list),np.array(lengths_list),np.array(tid_list),np.array(rayid_list)   \n",
    "\n",
    "def find_all_matches_tile16x16(hash_dict1, hash_dict2, thread_list1, thread_list2):\n",
    "  matches_list = []\n",
    "  lengths_list = []\n",
    "  tid_list = []\n",
    "  rayid_list = []\n",
    "  count = 0\n",
    "  for hash2,hash_list2 in hash_dict2.items():\n",
    "    for ray2 in hash_list2:\n",
    "      # count += 1\n",
    "      # if count > 10:\n",
    "      #   return np.array(matches_list),np.array(lengths_list),np.array(tid_list),np.array(rayid_list)\n",
    "      total_matches = 0\n",
    "      num_matching_hashes = 0\n",
    "      ray2x = ray2.tid%128\n",
    "      ray2y = ray2.tid//128\n",
    "      tilex = ray2x-ray2x%16\n",
    "      tiley = ray2y-ray2y%16\n",
    "      #print(f\"ray2: {ray2x},{ray2y},{tilex},{tiley}\")\n",
    "      ray2_len = len(thread_list2[ray2.tid][ray2.rayid].mem_entries)\n",
    "      for ray1 in hash_dict1[hash2]:\n",
    "        ray1x = ray1.tid%128\n",
    "        ray1y = ray1.tid//128\n",
    "        #print(f\"ray1: {ray1x},{ray1y}\")\n",
    "        if (ray1x-tilex >= 0 and ray1x-tilex < 16 and ray1y-tiley >= 0 and ray1y-tiley < 16):\n",
    "          matches = check_matches(thread_list1[ray1.tid][ray1.rayid].mem_entries, thread_list2[ray2.tid][ray2.rayid].mem_entries)\n",
    "          total_matches += matches\n",
    "          num_matching_hashes += 1\n",
    "      num_matching_hashes = num_matching_hashes if num_matching_hashes > 0 else 1\n",
    "      matches_list.append(np.int32(np.ceil(total_matches/num_matching_hashes)))\n",
    "      lengths_list.append(ray2_len)\n",
    "\n",
    "  return np.array(matches_list),np.array(lengths_list),np.array(tid_list),np.array(rayid_list)   \n",
    "\n",
    "def dump_scene_threadlist_pickle(thread_list1,thread_list2,scene: str):\n",
    "  with open(f'{scene}_left_threadlist.pickle', 'wb') as f:\n",
    "    pickle.dump(thread_list1, f)\n",
    "\n",
    "  with open(f'{scene}_right_threadlist.pickle', 'wb') as f:\n",
    "    pickle.dump(thread_list2, f)\n",
    "\n",
    "def dump_scene_hashlist_pickle(hash_list1,hash_list2,scene: str,hash_label: str):\n",
    "  with open(f'{scene}_left_{hash_label}_hashlist.pickle', 'wb') as f:\n",
    "    pickle.dump(hash_list1, f)\n",
    "\n",
    "  with open(f'{scene}_right_{hash_label}_hashlist.pickle', 'wb') as f:\n",
    "    pickle.dump(hash_list2, f)\n",
    "\n",
    "def load_scene_threadlist_pickle(scene: str):\n",
    "  with open(f'{scene}_left_threadlist.pickle', 'rb') as f:\n",
    "    thread_list1 = pickle.load(f)\n",
    "\n",
    "  with open(f'{scene}_right_threadlist.pickle', 'rb') as f:\n",
    "    thread_list2 = pickle.load(f)\n",
    "\n",
    "  return thread_list1, thread_list2\n",
    "\n",
    "def load_scene_hashlist_pickle(scene: str, hash_label: str):\n",
    "  with open(f'{scene}_left_{hash_label}_hashlist.pickle', 'rb') as f:\n",
    "    hash_list1 = pickle.load(f)\n",
    "\n",
    "  with open(f'{scene}_right_{hash_label}_hashlist.pickle', 'rb') as f:\n",
    "    hash_list2 = pickle.load(f)\n",
    "\n",
    "  return hash_list1,hash_list2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sponza\n",
      "Parsing the csv...\n",
      "Finished parsing the csv...\n",
      "Parsing the csv...\n",
      "Finished parsing the csv...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# thread_list1,thread_list2,min_val,max_val = load_sponza_stereo()\n",
    "# hash_list1 = hash_rays(thread_list1,min_val,max_val,5,3)\n",
    "# hash_list2 = hash_rays(thread_list2,min_val,max_val,5,3)\n",
    "# dump_scene_pickle(thread_list1,thread_list2,hash_list1,hash_list2,\"sponza\")\n",
    "#min_val = np.array([-1105.42603,-126.442497,-1920.94592]) # sponza min values\n",
    "#max_val = np.array([1198.57397,1433.5575,1807.05408]) # sponza max values\n",
    "\n",
    "#thread_list1,thread_list2 =  load_scene_threadlist_pickle(\"sponza\")\n",
    "thread_list1,thread_list2,min_val,max_val =  load_sponza_stereo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashing rays...(15 bits)\n",
      "Hashing rays...(15 bits)\n"
     ]
    }
   ],
   "source": [
    "hash_dict1 = hash_rays(thread_list1,min_val,max_val,5,3)\n",
    "hash_dict2 = hash_rays(thread_list2,min_val,max_val,5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashing rays randomly...(15 bits)\n",
      "Hashing rays randomly...(15 bits)\n"
     ]
    }
   ],
   "source": [
    "hash_dict_random = hash_rays_random(thread_list1,5,3)\n",
    "hash_dict_random = hash_rays_random(thread_list2,5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hash_dict_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m_near,l_near,t_near,r_near \u001b[38;5;241m=\u001b[39m find_all_matches_nearest(\u001b[43mhash_dict_random\u001b[49m, hash_dict_random, thread_list1, thread_list2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hash_dict_random' is not defined"
     ]
    }
   ],
   "source": [
    "m_near,l_near,t_near,r_near = find_all_matches_nearest(hash_dict_random, hash_dict_random, thread_list1, thread_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_best,l_best,t_best,r_best = find_all_matches_best(hash_dict_random, hash_dict_random, thread_list1, thread_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_near,l_near,t_near,r_near = find_all_matches_nearest(hash_dict1, hash_dict2, thread_list1, thread_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_best,l_best,t_best,r_best = find_all_matches_best(hash_dict1, hash_dict2, thread_list1, thread_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tile,l_tile,t_tile,r_tile = find_all_matches_tile16x16(hash_dict1, hash_dict2, thread_list1, thread_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3229624318065479\n",
      "0.49288431423841306\n",
      "0.25615429610968715\n"
     ]
    }
   ],
   "source": [
    "z_near=np.array(m_near)/np.array(l_near)\n",
    "print(np.mean(z_near))\n",
    "z_best=m_best/l_best\n",
    "print(np.mean(z_best))\n",
    "z_tile=m_tile/l_tile\n",
    "print(np.mean(z_tile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray_data instance: 9230, -15.0, 115.0, 2.0, -0.474376, -0.0818315, -0.876511\n",
      "ray_data instance: 9230, -198.195, 83.3983, -336.491, 0.910578, 0.333852, -0.122277\n",
      "ray_data instance: 9230, 275.71, 257.15, -400.13, -0.429041, -0.213575, 0.106061\n",
      "ray_data instance: 9230, -15.0, 115.0, 2.0, -0.477716, -0.0808743, -0.874784\n",
      "ray_data instance: 9230, -199.08, 83.8365, -335.083, 1.14181, 0.7512, 0.27766\n",
      "ray_data instance: 9230, 235.107, 369.49, -229.499, -0.480142, -0.592313, 0.445074\n",
      "mem_entry instance: ['0xd3fb1c00', 64, 0]\n",
      "mem_entry instance: ['0xd3fb1c40', 64, 1]\n",
      "mem_entry instance: ['0xd3fb1c80', 128, 2]\n",
      "mem_entry instance: ['0xd0eaba00', 64, 0]\n",
      "mem_entry instance: ['0xd0eaba40', 64, 1]\n",
      "mem_entry instance: ['0xd0eaba80', 64, 1]\n",
      "mem_entry instance: ['0xd0eabc00', 64, 1]\n",
      "mem_entry instance: ['0xd0eabdc0', 64, 1]\n",
      "mem_entry instance: ['0xd16bc6c0', 64, 1]\n",
      "mem_entry instance: ['0xd16bc840', 64, 1]\n",
      "mem_entry instance: ['0xd16bc9c0', 64, 1]\n",
      "mem_entry instance: ['0xd16bcc00', 64, 1]\n",
      "mem_entry instance: ['0xd176ce40', 64, 1]\n",
      "mem_entry instance: ['0xd1782440', 64, 1]\n",
      "mem_entry instance: ['0xd1783cc0', 64, 1]\n",
      "mem_entry instance: ['0xd1784280', 8, 3]\n",
      "mem_entry instance: ['0xd1784280', 64, 4]\n",
      "mem_entry instance: ['0xd1784200', 8, 3]\n",
      "mem_entry instance: ['0xd1784200', 64, 4]\n",
      "mem_entry instance: ['0xd1783d40', 64, 1]\n",
      "mem_entry instance: ['0xd1784480', 8, 3]\n",
      "mem_entry instance: ['0xd1784480', 64, 4]\n",
      "mem_entry instance: ['0xd1784400', 8, 3]\n",
      "mem_entry instance: ['0xd1784400', 64, 4]\n",
      "mem_entry instance: ['0xd16bc940', 64, 1]\n",
      "mem_entry instance: ['0xd1be1040', 64, 1]\n",
      "mem_entry instance: ['0xd1be1080', 64, 1]\n",
      "mem_entry instance: ['0xd1bef900', 64, 1]\n",
      "mem_entry instance: ['0xd1bf0dc0', 8, 3]\n",
      "mem_entry instance: ['0xd1bf0dc0', 64, 5]\n",
      "mem_entry instance: ['0xd1bf0d80', 8, 3]\n",
      "mem_entry instance: ['0xd1bf0d80', 64, 4]\n",
      "mem_entry instance: ['0xd16bc880', 64, 1]\n",
      "mem_entry instance: ['0xd195fc00', 64, 1]\n",
      "mem_entry instance: ['0xd195fd00', 64, 1]\n",
      "mem_entry instance: ['0xd195fcc0', 64, 1]\n",
      "mem_entry instance: ['0xd1b5d8c0', 64, 1]\n",
      "mem_entry instance: ['0xd1b6efc0', 64, 1]\n",
      "mem_entry instance: ['0xd1b78640', 64, 1]\n",
      "mem_entry instance: ['0xd1b786c0', 64, 1]\n",
      "mem_entry instance: ['0xd1b798c0', 8, 3]\n",
      "mem_entry instance: ['0xd1b798c0', 64, 5]\n",
      "mem_entry instance: ['0xd1b79880', 8, 3]\n",
      "mem_entry instance: ['0xd1b79880', 64, 5]\n",
      "mem_entry instance: ['0xd1b79840', 8, 3]\n",
      "mem_entry instance: ['0xd1b79840', 64, 4]\n",
      "mem_entry instance: ['0xd1b79800', 8, 3]\n",
      "mem_entry instance: ['0xd1b79800', 64, 4]\n",
      "mem_entry instance: ['0xd16bc740', 64, 1]\n",
      "mem_entry instance: ['0xd16bc700', 64, 1]\n",
      "mem_entry instance: ['0xd0eabec0', 64, 1]\n",
      "mem_entry instance: ['0xd0eabe80', 64, 1]\n",
      "mem_entry instance: ['0xd0eabbc0', 64, 1]\n",
      "mem_entry instance: ['0xd0eabb80', 64, 1]\n",
      "###\n",
      "mem_entry instance: ['0xd3fb1c00', 64, 0]\n",
      "mem_entry instance: ['0xd3fb1c40', 64, 1]\n",
      "mem_entry instance: ['0xd3fb1c80', 128, 2]\n",
      "mem_entry instance: ['0xd0eaba00', 64, 0]\n",
      "mem_entry instance: ['0xd0eaba40', 64, 1]\n",
      "mem_entry instance: ['0xd0eaba80', 64, 1]\n",
      "mem_entry instance: ['0xd0eabc00', 64, 1]\n",
      "mem_entry instance: ['0xd0eabd80', 64, 1]\n",
      "mem_entry instance: ['0xd0eabec0', 64, 1]\n",
      "mem_entry instance: ['0xd1f1ae00', 64, 1]\n",
      "mem_entry instance: ['0xd1f1e700', 8, 3]\n",
      "mem_entry instance: ['0xd1f1e700', 64, 4]\n",
      "mem_entry instance: ['0xd1f1e6c0', 8, 3]\n",
      "mem_entry instance: ['0xd1f1e6c0', 64, 5]\n",
      "mem_entry instance: ['0xd1f1e680', 8, 3]\n",
      "mem_entry instance: ['0xd1f1e680', 64, 5]\n",
      "mem_entry instance: ['0xd1f1e640', 8, 3]\n",
      "mem_entry instance: ['0xd1f1e640', 64, 4]\n",
      "mem_entry instance: ['0xd1f1ae80', 64, 1]\n",
      "mem_entry instance: ['0xd1f1ee00', 8, 3]\n",
      "mem_entry instance: ['0xd1f1ee00', 64, 5]\n",
      "mem_entry instance: ['0xd1f1edc0', 8, 3]\n",
      "mem_entry instance: ['0xd1f1edc0', 64, 4]\n",
      "mem_entry instance: ['0xd0eabe80', 64, 1]\n",
      "mem_entry instance: ['0xd0eabe00', 64, 1]\n",
      "mem_entry instance: ['0xd0eabdc0', 64, 1]\n",
      "mem_entry instance: ['0xd16bc6c0', 64, 1]\n",
      "mem_entry instance: ['0xd16bc840', 64, 1]\n",
      "mem_entry instance: ['0xd16bc9c0', 64, 1]\n",
      "mem_entry instance: ['0xd16bcc00', 64, 1]\n",
      "mem_entry instance: ['0xd176ce40', 64, 1]\n",
      "mem_entry instance: ['0xd1782440', 64, 1]\n",
      "mem_entry instance: ['0xd1783d40', 64, 1]\n",
      "mem_entry instance: ['0xd1784480', 8, 3]\n",
      "mem_entry instance: ['0xd1784480', 64, 4]\n",
      "mem_entry instance: ['0xd1784400', 8, 3]\n",
      "mem_entry instance: ['0xd1784400', 64, 4]\n",
      "mem_entry instance: ['0xd16bc880', 64, 1]\n",
      "mem_entry instance: ['0xd195fc80', 64, 1]\n",
      "mem_entry instance: ['0xd195fd00', 64, 1]\n",
      "mem_entry instance: ['0xd1b8b0c0', 64, 1]\n",
      "mem_entry instance: ['0xd1b8b280', 64, 1]\n",
      "mem_entry instance: ['0xd1b92140', 64, 1]\n",
      "mem_entry instance: ['0xd1b93940', 64, 1]\n",
      "mem_entry instance: ['0xd1b94000', 64, 1]\n",
      "mem_entry instance: ['0xd1b941c0', 8, 3]\n",
      "mem_entry instance: ['0xd1b941c0', 64, 4]\n",
      "mem_entry instance: ['0xd1b94180', 8, 3]\n",
      "mem_entry instance: ['0xd1b94180', 64, 5]\n",
      "mem_entry instance: ['0xd1b940c0', 64, 1]\n",
      "mem_entry instance: ['0xd1b93980', 64, 1]\n",
      "mem_entry instance: ['0xd1b92200', 64, 1]\n",
      "mem_entry instance: ['0xd1b96e40', 64, 1]\n",
      "mem_entry instance: ['0xd1b8b200', 64, 1]\n",
      "mem_entry instance: ['0xd1b8b1c0', 64, 1]\n",
      "mem_entry instance: ['0xd16bc740', 64, 1]\n",
      "mem_entry instance: ['0xd16bc700', 64, 1]\n",
      "mem_entry instance: ['0xd0eabbc0', 64, 1]\n",
      "mem_entry instance: ['0xd0eabb80', 64, 1]\n",
      "mem_entry instance: ['0xd0eabb40', 64, 1]\n",
      "mem_entry instance: ['0xd0eabb00', 64, 1]\n",
      "mem_entry instance: ['0xd0eabac0', 64, 1]\n",
      "7\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "tid = 9230\n",
    "for obj in thread_list1[tid]:\n",
    "  print(obj.ray_data)\n",
    "print('\\n'.join(str(entry) for entry in thread_list1[tid][1].mem_entries))\n",
    "print(\"###\")\n",
    "print('\\n'.join(str(entry) for entry in thread_list1[tid][4].mem_entries))\n",
    "\n",
    "a = check_matches(thread_list1[tid][1].mem_entries, thread_list1[tid][4].mem_entries)\n",
    "print(a)\n",
    "print(len(thread_list1[tid][1].mem_entries))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
